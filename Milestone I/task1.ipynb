{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Milestone I Natural Language Processing\n",
    "## Task 1. Basic Text Pre-processing\n",
    "#### Student Name: Arya Ramesh Patil\n",
    "#### Student ID: S4060675\n",
    "\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used:\n",
    "* pandas\n",
    "* numpy\n",
    "* nltk\n",
    "* chain\n",
    "* division\n",
    "\n",
    "## Introduction\n",
    "This part of assessment primarily focuses on text pre-processing. While pre-processing also involves stemming & lemmatisation, sentence segmentation, here we focus on tokenisation, case normalisation, removal of stop words and most/less frequent words. Without basic text pre-processing, it is difficult to build a working machine learning model. The activities and lecture slides of week 7 helped me thoroughly to understand the text pre-processing steps in depth and assisted me to develop the code for this particular part of the assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import RegexpTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from itertools import chain\n",
    "from __future__ import division\n",
    "from nltk.probability import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Examining and loading data\n",
    "On loading the csv file into pandas dataframe, it is observed that the file has 19662 rows and 10 columns. As per the specifications, task 1 involves working on 'Review Text' column. The column 'Review Text' consists of string of words that represent a review on a clothing item. In order to work on this column, I extracted the column in review_text variable to perform pre-processing steps as given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigning file name to csv_file variable\n",
    "csv_file = 'assignment3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the said csv file into a dataframe\n",
    "clothes_review_data = pd.read_csv(csv_file, sep = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1080</td>\n",
       "      <td>49</td>\n",
       "      <td>Not for the very petite</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858</td>\n",
       "      <td>39</td>\n",
       "      <td>Cagrcoal shimmer fun</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19657</th>\n",
       "      <td>1104</td>\n",
       "      <td>34</td>\n",
       "      <td>Great dress for many occasions</td>\n",
       "      <td>I was very happy to snag this dress at such a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19658</th>\n",
       "      <td>862</td>\n",
       "      <td>48</td>\n",
       "      <td>Wish it was made of cotton</td>\n",
       "      <td>It reminds me of maternity clothes. soft, stre...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19659</th>\n",
       "      <td>1104</td>\n",
       "      <td>31</td>\n",
       "      <td>Cute, but see through</td>\n",
       "      <td>This fit well, but the top was very see throug...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>1084</td>\n",
       "      <td>28</td>\n",
       "      <td>Very cute dress, perfect for summer parties an...</td>\n",
       "      <td>I bought this dress for a wedding i have this ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19661</th>\n",
       "      <td>1104</td>\n",
       "      <td>52</td>\n",
       "      <td>Please make more like this one!</td>\n",
       "      <td>This dress in a lovely platinum is feminine an...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19662 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clothing ID  Age                                              Title  \\\n",
       "0             1077   60                            Some major design flaws   \n",
       "1             1049   50                                   My favorite buy!   \n",
       "2              847   47                                   Flattering shirt   \n",
       "3             1080   49                            Not for the very petite   \n",
       "4              858   39                               Cagrcoal shimmer fun   \n",
       "...            ...  ...                                                ...   \n",
       "19657         1104   34                     Great dress for many occasions   \n",
       "19658          862   48                         Wish it was made of cotton   \n",
       "19659         1104   31                              Cute, but see through   \n",
       "19660         1084   28  Very cute dress, perfect for summer parties an...   \n",
       "19661         1104   52                    Please make more like this one!   \n",
       "\n",
       "                                             Review Text  Rating  \\\n",
       "0      I had such high hopes for this dress and reall...       3   \n",
       "1      I love, love, love this jumpsuit. it's fun, fl...       5   \n",
       "2      This shirt is very flattering to all due to th...       5   \n",
       "3      I love tracy reese dresses, but this one is no...       2   \n",
       "4      I aded this in my basket at hte last mintue to...       5   \n",
       "...                                                  ...     ...   \n",
       "19657  I was very happy to snag this dress at such a ...       5   \n",
       "19658  It reminds me of maternity clothes. soft, stre...       3   \n",
       "19659  This fit well, but the top was very see throug...       3   \n",
       "19660  I bought this dress for a wedding i have this ...       3   \n",
       "19661  This dress in a lovely platinum is feminine an...       5   \n",
       "\n",
       "       Recommended IND  Positive Feedback Count   Division Name  \\\n",
       "0                    0                        0         General   \n",
       "1                    1                        0  General Petite   \n",
       "2                    1                        6         General   \n",
       "3                    0                        4         General   \n",
       "4                    1                        1  General Petite   \n",
       "...                ...                      ...             ...   \n",
       "19657                1                        0  General Petite   \n",
       "19658                1                        0  General Petite   \n",
       "19659                0                        1  General Petite   \n",
       "19660                1                        2         General   \n",
       "19661                1                       22  General Petite   \n",
       "\n",
       "      Department Name Class Name  \n",
       "0             Dresses    Dresses  \n",
       "1             Bottoms      Pants  \n",
       "2                Tops    Blouses  \n",
       "3             Dresses    Dresses  \n",
       "4                Tops      Knits  \n",
       "...               ...        ...  \n",
       "19657         Dresses    Dresses  \n",
       "19658            Tops      Knits  \n",
       "19659         Dresses    Dresses  \n",
       "19660         Dresses    Dresses  \n",
       "19661         Dresses    Dresses  \n",
       "\n",
       "[19662 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the data\n",
    "clothes_review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting the 'Review Text' column for pre-processing\n",
    "review_text = clothes_review_data['Review Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        I had such high hopes for this dress and reall...\n",
       "1        I love, love, love this jumpsuit. it's fun, fl...\n",
       "2        This shirt is very flattering to all due to th...\n",
       "3        I love tracy reese dresses, but this one is no...\n",
       "4        I aded this in my basket at hte last mintue to...\n",
       "                               ...                        \n",
       "19657    I was very happy to snag this dress at such a ...\n",
       "19658    It reminds me of maternity clothes. soft, stre...\n",
       "19659    This fit well, but the top was very see throug...\n",
       "19660    I bought this dress for a wedding i have this ...\n",
       "19661    This dress in a lovely platinum is feminine an...\n",
       "Name: Review Text, Length: 19662, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the data\n",
    "review_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Pre-processing data\n",
    "The required text pre-processing steps are:\n",
    "* Case Normalisation: All the text is converted into lowercase.\n",
    "* Tokenisation: Splitting the reviews into tokens.\n",
    "* Removing words based on given conditions:\n",
    "  - Removing words with length less than 2\n",
    "  - Removing stopwords from given stopwords_en.txt file\n",
    "  - Removing words based on term frequency\n",
    "  - Removing words based on document frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case Normalisation and Tokenisation\n",
    "Here I defined a function 'tokenize_reviews' to perform case normalisation and split the reviews into tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] w07_act1_gen_feat_vec - cell 5\n",
    "# function for case normalisation and tokensisation\n",
    "def tokenize_reviews(review_text):\n",
    "    nl_review = review_text.lower() # converting reviews to lowercase\n",
    "    pattern = r\"[a-zA-Z]+(?:[-'][a-zA-Z]+)?\" # regex pattern to tokenise the reviews\n",
    "    tokenizer = RegexpTokenizer(pattern) # tokeniser to split the reviews based on the regex pattern\n",
    "    tokenized_review = tokenizer.tokenize(nl_review) # passing normalised reviews to get list of tokens\n",
    "    return tokenized_review # returning cleaned list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [i, had, such, high, hopes, for, this, dress, ...\n",
       "1        [i, love, love, love, this, jumpsuit, it's, fu...\n",
       "2        [this, shirt, is, very, flattering, to, all, d...\n",
       "3        [i, love, tracy, reese, dresses, but, this, on...\n",
       "4        [i, aded, this, in, my, basket, at, hte, last,...\n",
       "                               ...                        \n",
       "19657    [i, was, very, happy, to, snag, this, dress, a...\n",
       "19658    [it, reminds, me, of, maternity, clothes, soft...\n",
       "19659    [this, fit, well, but, the, top, was, very, se...\n",
       "19660    [i, bought, this, dress, for, a, wedding, i, h...\n",
       "19661    [this, dress, in, a, lovely, platinum, is, fem...\n",
       "Name: Review Text, Length: 19662, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_reviews = review_text.apply(tokenize_reviews) # applying the function to get cleaned list of tokens # [2]\n",
    "tokenized_reviews # checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] w07_act1_gen_feat_vec.ipynb - cell 8\n",
    "# statistics to get an idea of document length, number of tokens, vocabulary size\n",
    "def stats_print(tokenized_reviews):\n",
    "    words = list(chain.from_iterable(tokenized_reviews)) # putting tokens in single list\n",
    "    vocab = set(words) # getting set of unique words\n",
    "    lexical_diversity = len(vocab)/len(words) # ratio of unique words to total words\n",
    "    print(\"Vocabulary size: \",len(vocab))\n",
    "    print(\"Total number of tokens: \", len(words))\n",
    "    print(\"Lexical diversity: \", lexical_diversity)\n",
    "    print(\"Total number of reviews:\", len(tokenized_reviews))\n",
    "    lens = [len(article) for article in tokenized_reviews] # calculating length of each review\n",
    "    print(\"Average document length:\", np.mean(lens))\n",
    "    print(\"Maximum document length:\", np.max(lens))\n",
    "    print(\"Minimum document length:\", np.min(lens))\n",
    "    print(\"Standard deviation of document length:\", np.std(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  14806\n",
      "Total number of tokens:  1206688\n",
      "Lexical diversity:  0.012269948818584423\n",
      "Total number of reviews: 19662\n",
      "Average document length: 61.37157969687723\n",
      "Maximum document length: 113\n",
      "Minimum document length: 2\n",
      "Standard deviation of document length: 27.802596969841698\n"
     ]
    }
   ],
   "source": [
    "stats_print(tokenized_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_file = \"stopwords_en.txt\" #loading the stopwords file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " \"a's\",\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'across',\n",
       " 'actually',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " \"ain't\",\n",
       " 'all',\n",
       " 'allow',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'appear',\n",
       " 'appreciate',\n",
       " 'appropriate',\n",
       " 'are',\n",
       " \"aren't\",\n",
       " 'around',\n",
       " 'as',\n",
       " 'aside',\n",
       " 'ask',\n",
       " 'asking',\n",
       " 'associated',\n",
       " 'at',\n",
       " 'available',\n",
       " 'away',\n",
       " 'awfully',\n",
       " 'b',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'brief',\n",
       " 'but',\n",
       " 'by',\n",
       " 'c',\n",
       " \"c'mon\",\n",
       " \"c's\",\n",
       " 'came',\n",
       " 'can',\n",
       " \"can't\",\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'cause',\n",
       " 'causes',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'changes',\n",
       " 'clearly',\n",
       " 'co',\n",
       " 'com',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'concerning',\n",
       " 'consequently',\n",
       " 'consider',\n",
       " 'considering',\n",
       " 'contain',\n",
       " 'containing',\n",
       " 'contains',\n",
       " 'corresponding',\n",
       " 'could',\n",
       " \"couldn't\",\n",
       " 'course',\n",
       " 'currently',\n",
       " 'd',\n",
       " 'definitely',\n",
       " 'described',\n",
       " 'despite',\n",
       " 'did',\n",
       " \"didn't\",\n",
       " 'different',\n",
       " 'do',\n",
       " 'does',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " \"don't\",\n",
       " 'done',\n",
       " 'down',\n",
       " 'downwards',\n",
       " 'during',\n",
       " 'e',\n",
       " 'each',\n",
       " 'edu',\n",
       " 'eg',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'enough',\n",
       " 'entirely',\n",
       " 'especially',\n",
       " 'et',\n",
       " 'etc',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'ex',\n",
       " 'exactly',\n",
       " 'example',\n",
       " 'except',\n",
       " 'f',\n",
       " 'far',\n",
       " 'few',\n",
       " 'fifth',\n",
       " 'first',\n",
       " 'five',\n",
       " 'followed',\n",
       " 'following',\n",
       " 'follows',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forth',\n",
       " 'four',\n",
       " 'from',\n",
       " 'further',\n",
       " 'furthermore',\n",
       " 'g',\n",
       " 'get',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'go',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'greetings',\n",
       " 'h',\n",
       " 'had',\n",
       " \"hadn't\",\n",
       " 'happens',\n",
       " 'hardly',\n",
       " 'has',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he's\",\n",
       " 'hello',\n",
       " 'help',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " \"here's\",\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'hi',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'hither',\n",
       " 'hopefully',\n",
       " 'how',\n",
       " 'howbeit',\n",
       " 'however',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " \"i've\",\n",
       " 'ie',\n",
       " 'if',\n",
       " 'ignored',\n",
       " 'immediate',\n",
       " 'in',\n",
       " 'inasmuch',\n",
       " 'inc',\n",
       " 'indeed',\n",
       " 'indicate',\n",
       " 'indicated',\n",
       " 'indicates',\n",
       " 'inner',\n",
       " 'insofar',\n",
       " 'instead',\n",
       " 'into',\n",
       " 'inward',\n",
       " 'is',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'j',\n",
       " 'just',\n",
       " 'k',\n",
       " 'keep',\n",
       " 'keeps',\n",
       " 'kept',\n",
       " 'know',\n",
       " 'knows',\n",
       " 'known',\n",
       " 'l',\n",
       " 'last',\n",
       " 'lately',\n",
       " 'later',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'lest',\n",
       " 'let',\n",
       " \"let's\",\n",
       " 'like',\n",
       " 'liked',\n",
       " 'likely',\n",
       " 'little',\n",
       " 'look',\n",
       " 'looking',\n",
       " 'looks',\n",
       " 'ltd',\n",
       " 'm',\n",
       " 'mainly',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meanwhile',\n",
       " 'merely',\n",
       " 'might',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'n',\n",
       " 'name',\n",
       " 'namely',\n",
       " 'nd',\n",
       " 'near',\n",
       " 'nearly',\n",
       " 'necessary',\n",
       " 'need',\n",
       " 'needs',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'non',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'normally',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'novel',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'o',\n",
       " 'obviously',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'oh',\n",
       " 'ok',\n",
       " 'okay',\n",
       " 'old',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'ones',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'ought',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'outside',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'own',\n",
       " 'p',\n",
       " 'particular',\n",
       " 'particularly',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'placed',\n",
       " 'please',\n",
       " 'plus',\n",
       " 'possible',\n",
       " 'presumably',\n",
       " 'probably',\n",
       " 'provides',\n",
       " 'q',\n",
       " 'que',\n",
       " 'quite',\n",
       " 'qv',\n",
       " 'r',\n",
       " 'rather',\n",
       " 'rd',\n",
       " 're',\n",
       " 'really',\n",
       " 'reasonably',\n",
       " 'regarding',\n",
       " 'regardless',\n",
       " 'regards',\n",
       " 'relatively',\n",
       " 'respectively',\n",
       " 'right',\n",
       " 's',\n",
       " 'said',\n",
       " 'same',\n",
       " 'saw',\n",
       " 'say',\n",
       " 'saying',\n",
       " 'says',\n",
       " 'second',\n",
       " 'secondly',\n",
       " 'see',\n",
       " 'seeing',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'seen',\n",
       " 'self',\n",
       " 'selves',\n",
       " 'sensible',\n",
       " 'sent',\n",
       " 'serious',\n",
       " 'seriously',\n",
       " 'seven',\n",
       " 'several',\n",
       " 'shall',\n",
       " 'she',\n",
       " 'should',\n",
       " \"shouldn't\",\n",
       " 'since',\n",
       " 'six',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somebody',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'somewhere',\n",
       " 'soon',\n",
       " 'sorry',\n",
       " 'specified',\n",
       " 'specify',\n",
       " 'specifying',\n",
       " 'still',\n",
       " 'sub',\n",
       " 'such',\n",
       " 'sup',\n",
       " 'sure',\n",
       " 't',\n",
       " \"t's\",\n",
       " 'take',\n",
       " 'taken',\n",
       " 'tell',\n",
       " 'tends',\n",
       " 'th',\n",
       " 'than',\n",
       " 'thank',\n",
       " 'thanks',\n",
       " 'thanx',\n",
       " 'that',\n",
       " \"that's\",\n",
       " 'thats',\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " \"there's\",\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'theres',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'think',\n",
       " 'third',\n",
       " 'this',\n",
       " 'thorough',\n",
       " 'thoroughly',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'took',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'tried',\n",
       " 'tries',\n",
       " 'truly',\n",
       " 'try',\n",
       " 'trying',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'u',\n",
       " 'un',\n",
       " 'under',\n",
       " 'unfortunately',\n",
       " 'unless',\n",
       " 'unlikely',\n",
       " 'until',\n",
       " 'unto',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'use',\n",
       " 'used',\n",
       " 'useful',\n",
       " 'uses',\n",
       " 'using',\n",
       " 'usually',\n",
       " 'uucp',\n",
       " 'v',\n",
       " 'value',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'viz',\n",
       " 'vs',\n",
       " 'w',\n",
       " 'want',\n",
       " 'wants',\n",
       " 'was',\n",
       " \"wasn't\",\n",
       " 'way',\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " \"we've\",\n",
       " 'welcome',\n",
       " 'well',\n",
       " 'went',\n",
       " 'were',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " \"what's\",\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " \"where's\",\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " \"who's\",\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'willing',\n",
       " 'wish',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " \"won't\",\n",
       " 'wonder',\n",
       " 'would',\n",
       " 'would',\n",
       " \"wouldn't\",\n",
       " 'x',\n",
       " 'y',\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'z',\n",
       " 'zero']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1] w07_act1_gen_feat_vec.ipynb - cell 16\n",
    "# reading the file \n",
    "with open(stopwords_file, 'r') as file: # opens file in read mode\n",
    "    stopwords = file.read().splitlines() # splits into line such that there is one stopwword per line\n",
    "stopwords # checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting unique stopwords\n",
    "stopwords = set(stopwords)\n",
    "len(stopwords) # checking the number of stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing words\n",
    "Here I defined a function 'remove_words' to remove words based on the given conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for removal of words\n",
    "def remove_words(tokens, stopwords):\n",
    "    tokens = [token for token in tokens if len(token) >= 2] # removing words with the length less than 2\n",
    "    tokens = [token for token in tokens if token not in stopwords] # removing stopwords \n",
    "    return tokens # returning cleaned list of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [high, hopes, dress, wanted, work, initially, ...\n",
       "1        [love, love, love, jumpsuit, fun, flirty, fabu...\n",
       "2        [shirt, flattering, due, adjustable, front, ti...\n",
       "3        [love, tracy, reese, dresses, petite, feet, ta...\n",
       "4        [aded, basket, hte, mintue, person, store, pic...\n",
       "                               ...                        \n",
       "19657    [happy, snag, dress, great, price, easy, slip,...\n",
       "19658    [reminds, maternity, clothes, soft, stretchy, ...\n",
       "19659    [fit, top, worked, glad, store, order, online,...\n",
       "19660    [bought, dress, wedding, summer, cute, fit, pe...\n",
       "19661    [dress, lovely, platinum, feminine, fits, perf...\n",
       "Name: Review Text, Length: 19662, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying the function on tokenized reviews to remove the words on said condition\n",
    "cleaned_reviews = tokenized_reviews.apply(lambda tokens: remove_words(tokens, stopwords)) # [2]\n",
    "cleaned_reviews # checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  14283\n",
      "Total number of tokens:  452692\n",
      "Lexical diversity:  0.031551253390826435\n",
      "Total number of reviews: 19662\n",
      "Average document length: 23.023700539110976\n",
      "Maximum document length: 51\n",
      "Minimum document length: 1\n",
      "Standard deviation of document length: 10.165913222944233\n"
     ]
    }
   ],
   "source": [
    "stats_print(cleaned_reviews) # statistics on cleaned reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] w07_act1_gen_feat_vec.ipynb - cell 11\n",
    "words = list(chain.from_iterable(cleaned_reviews)) # putting tokens in single list\n",
    "vocab = set(words) # getting set of unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452692"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words) # checking the number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14283"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab) # checking the number of unique tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] w07_act1_gen_feat_vec.ipynb - cell 12\n",
    "term_fd = FreqDist(words) # computing term frequency for each unique word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'dress': 9334, 'size': 7860, 'love': 7722, 'fit': 6582, 'top': 6542, 'wear': 5715, 'great': 5302, 'fabric': 4306, 'color': 4099, 'small': 4097, ...})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_fd # checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the words that only appear once in the document collection\n",
    "term_freq = cleaned_reviews.apply(lambda tokens: [word for word in tokens if term_fd[word] > 1]) # [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [high, hopes, dress, wanted, work, initially, ...\n",
       "1        [love, love, love, jumpsuit, fun, flirty, fabu...\n",
       "2        [shirt, flattering, due, adjustable, front, ti...\n",
       "3        [love, tracy, reese, dresses, petite, feet, ta...\n",
       "4        [basket, hte, person, store, pick, teh, color,...\n",
       "                               ...                        \n",
       "19657    [happy, snag, dress, great, price, easy, slip,...\n",
       "19658    [reminds, maternity, clothes, soft, stretchy, ...\n",
       "19659    [fit, top, worked, glad, store, order, online,...\n",
       "19660    [bought, dress, wedding, summer, cute, fit, pe...\n",
       "19661    [dress, lovely, feminine, fits, perfectly, eas...\n",
       "Name: Review Text, Length: 19662, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_freq # checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'love': 6416, 'size': 5888, 'fit': 5537, 'dress': 5346, 'wear': 4900, 'top': 4670, 'great': 4497, 'fabric': 3712, 'color': 3604, 'small': 3265, ...})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1] w07_act1_gen_feat_vec.ipynb - cell 15\n",
    "words_2 = list(chain.from_iterable([set(review) for review in term_freq])) # putting unique tokens in single list\n",
    "doc_fd = FreqDist(words_2)  # computing document frequency for each unique word\n",
    "doc_fd # checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love',\n",
       " 'size',\n",
       " 'fit',\n",
       " 'dress',\n",
       " 'wear',\n",
       " 'top',\n",
       " 'great',\n",
       " 'fabric',\n",
       " 'color',\n",
       " 'small',\n",
       " 'ordered',\n",
       " 'perfect',\n",
       " 'flattering',\n",
       " 'soft',\n",
       " 'comfortable',\n",
       " 'back',\n",
       " 'cute',\n",
       " 'fits',\n",
       " 'nice',\n",
       " 'bought']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1] w07_act1_gen_feat_vec.ipynb - cell 15\n",
    "top20_freq_words =doc_fd.most_common(20) # computing the top 20 most common words \n",
    "top20_freq_words = [word for word, freq in top20_freq_words] # extracting only the words from doc_fd without their frequencies\n",
    "top20_freq_words # checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the top 20 most frequent words\n",
    "processed_reviews = term_freq.apply(lambda tokens: [word for word in tokens if word not in top20_freq_words]) # [2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [high, hopes, wanted, work, initially, petite,...\n",
       "1        [jumpsuit, fun, flirty, fabulous, time, compli...\n",
       "2        [shirt, due, adjustable, front, tie, length, l...\n",
       "3        [tracy, reese, dresses, petite, feet, tall, br...\n",
       "4        [basket, hte, person, store, pick, teh, pale, ...\n",
       "                               ...                        \n",
       "19657         [happy, snag, price, easy, slip, cut, combo]\n",
       "19658    [reminds, maternity, clothes, stretchy, shiny,...\n",
       "19659                 [worked, glad, store, order, online]\n",
       "19660    [wedding, summer, medium, waist, perfectly, lo...\n",
       "19661    [lovely, feminine, perfectly, easy, comfy, hig...\n",
       "Name: Review Text, Length: 19662, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_reviews # checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19662"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processed_reviews) # checking the number of reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  7529\n",
      "Total number of tokens:  355505\n",
      "Lexical diversity:  0.021178323792914306\n",
      "Total number of reviews: 19662\n",
      "Average document length: 18.080815786796865\n",
      "Maximum document length: 47\n",
      "Minimum document length: 0\n",
      "Standard deviation of document length: 8.833524535391433\n"
     ]
    }
   ],
   "source": [
    "stats_print(processed_reviews) # statistics on processed reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# noticed that minimum document length is 0, hence, computed the number of empty lists\n",
    "empty_lists = processed_reviews.apply(lambda x: len(x) == 0).sum() # [2]\n",
    "empty_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending processed_reviews column to the original dataframe\n",
    "clothes_review_data['Processed Review Text'] = processed_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Processed Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>[high, hopes, wanted, work, initially, petite,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>[jumpsuit, fun, flirty, fabulous, time, compli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>[shirt, due, adjustable, front, tie, length, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1080</td>\n",
       "      <td>49</td>\n",
       "      <td>Not for the very petite</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>[tracy, reese, dresses, petite, feet, tall, br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858</td>\n",
       "      <td>39</td>\n",
       "      <td>Cagrcoal shimmer fun</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "      <td>[basket, hte, person, store, pick, teh, pale, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19657</th>\n",
       "      <td>1104</td>\n",
       "      <td>34</td>\n",
       "      <td>Great dress for many occasions</td>\n",
       "      <td>I was very happy to snag this dress at such a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>[happy, snag, price, easy, slip, cut, combo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19658</th>\n",
       "      <td>862</td>\n",
       "      <td>48</td>\n",
       "      <td>Wish it was made of cotton</td>\n",
       "      <td>It reminds me of maternity clothes. soft, stre...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "      <td>[reminds, maternity, clothes, stretchy, shiny,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19659</th>\n",
       "      <td>1104</td>\n",
       "      <td>31</td>\n",
       "      <td>Cute, but see through</td>\n",
       "      <td>This fit well, but the top was very see throug...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>[worked, glad, store, order, online]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>1084</td>\n",
       "      <td>28</td>\n",
       "      <td>Very cute dress, perfect for summer parties an...</td>\n",
       "      <td>I bought this dress for a wedding i have this ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>[wedding, summer, medium, waist, perfectly, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19661</th>\n",
       "      <td>1104</td>\n",
       "      <td>52</td>\n",
       "      <td>Please make more like this one!</td>\n",
       "      <td>This dress in a lovely platinum is feminine an...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>[lovely, feminine, perfectly, easy, comfy, hig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19662 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clothing ID  Age                                              Title  \\\n",
       "0             1077   60                            Some major design flaws   \n",
       "1             1049   50                                   My favorite buy!   \n",
       "2              847   47                                   Flattering shirt   \n",
       "3             1080   49                            Not for the very petite   \n",
       "4              858   39                               Cagrcoal shimmer fun   \n",
       "...            ...  ...                                                ...   \n",
       "19657         1104   34                     Great dress for many occasions   \n",
       "19658          862   48                         Wish it was made of cotton   \n",
       "19659         1104   31                              Cute, but see through   \n",
       "19660         1084   28  Very cute dress, perfect for summer parties an...   \n",
       "19661         1104   52                    Please make more like this one!   \n",
       "\n",
       "                                             Review Text  Rating  \\\n",
       "0      I had such high hopes for this dress and reall...       3   \n",
       "1      I love, love, love this jumpsuit. it's fun, fl...       5   \n",
       "2      This shirt is very flattering to all due to th...       5   \n",
       "3      I love tracy reese dresses, but this one is no...       2   \n",
       "4      I aded this in my basket at hte last mintue to...       5   \n",
       "...                                                  ...     ...   \n",
       "19657  I was very happy to snag this dress at such a ...       5   \n",
       "19658  It reminds me of maternity clothes. soft, stre...       3   \n",
       "19659  This fit well, but the top was very see throug...       3   \n",
       "19660  I bought this dress for a wedding i have this ...       3   \n",
       "19661  This dress in a lovely platinum is feminine an...       5   \n",
       "\n",
       "       Recommended IND  Positive Feedback Count   Division Name  \\\n",
       "0                    0                        0         General   \n",
       "1                    1                        0  General Petite   \n",
       "2                    1                        6         General   \n",
       "3                    0                        4         General   \n",
       "4                    1                        1  General Petite   \n",
       "...                ...                      ...             ...   \n",
       "19657                1                        0  General Petite   \n",
       "19658                1                        0  General Petite   \n",
       "19659                0                        1  General Petite   \n",
       "19660                1                        2         General   \n",
       "19661                1                       22  General Petite   \n",
       "\n",
       "      Department Name Class Name  \\\n",
       "0             Dresses    Dresses   \n",
       "1             Bottoms      Pants   \n",
       "2                Tops    Blouses   \n",
       "3             Dresses    Dresses   \n",
       "4                Tops      Knits   \n",
       "...               ...        ...   \n",
       "19657         Dresses    Dresses   \n",
       "19658            Tops      Knits   \n",
       "19659         Dresses    Dresses   \n",
       "19660         Dresses    Dresses   \n",
       "19661         Dresses    Dresses   \n",
       "\n",
       "                                   Processed Review Text  \n",
       "0      [high, hopes, wanted, work, initially, petite,...  \n",
       "1      [jumpsuit, fun, flirty, fabulous, time, compli...  \n",
       "2      [shirt, due, adjustable, front, tie, length, l...  \n",
       "3      [tracy, reese, dresses, petite, feet, tall, br...  \n",
       "4      [basket, hte, person, store, pick, teh, pale, ...  \n",
       "...                                                  ...  \n",
       "19657       [happy, snag, price, easy, slip, cut, combo]  \n",
       "19658  [reminds, maternity, clothes, stretchy, shiny,...  \n",
       "19659               [worked, glad, store, order, online]  \n",
       "19660  [wedding, summer, medium, waist, perfectly, lo...  \n",
       "19661  [lovely, feminine, perfectly, easy, comfy, hig...  \n",
       "\n",
       "[19662 rows x 11 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clothes_review_data # checking the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am dropping reviews that result in empty lists because techniques for handling empty instances have not been covered yet. Additionally, there is no suitable way to replace empty reviews with meaningful content, as the data type is text. Furthermore, we were instructed to drop empty instances during the lectorial session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "      <th>Processed Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>[high, hopes, wanted, work, initially, petite,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "      <td>[jumpsuit, fun, flirty, fabulous, time, compli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "      <td>[shirt, due, adjustable, front, tie, length, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1080</td>\n",
       "      <td>49</td>\n",
       "      <td>Not for the very petite</td>\n",
       "      <td>I love tracy reese dresses, but this one is no...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>[tracy, reese, dresses, petite, feet, tall, br...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>858</td>\n",
       "      <td>39</td>\n",
       "      <td>Cagrcoal shimmer fun</td>\n",
       "      <td>I aded this in my basket at hte last mintue to...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "      <td>[basket, hte, person, store, pick, teh, pale, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19657</th>\n",
       "      <td>1104</td>\n",
       "      <td>34</td>\n",
       "      <td>Great dress for many occasions</td>\n",
       "      <td>I was very happy to snag this dress at such a ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>[happy, snag, price, easy, slip, cut, combo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19658</th>\n",
       "      <td>862</td>\n",
       "      <td>48</td>\n",
       "      <td>Wish it was made of cotton</td>\n",
       "      <td>It reminds me of maternity clothes. soft, stre...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "      <td>[reminds, maternity, clothes, stretchy, shiny,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19659</th>\n",
       "      <td>1104</td>\n",
       "      <td>31</td>\n",
       "      <td>Cute, but see through</td>\n",
       "      <td>This fit well, but the top was very see throug...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>[worked, glad, store, order, online]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19660</th>\n",
       "      <td>1084</td>\n",
       "      <td>28</td>\n",
       "      <td>Very cute dress, perfect for summer parties an...</td>\n",
       "      <td>I bought this dress for a wedding i have this ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>[wedding, summer, medium, waist, perfectly, lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19661</th>\n",
       "      <td>1104</td>\n",
       "      <td>52</td>\n",
       "      <td>Please make more like this one!</td>\n",
       "      <td>This dress in a lovely platinum is feminine an...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>[lovely, feminine, perfectly, easy, comfy, hig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19652 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clothing ID  Age                                              Title  \\\n",
       "0             1077   60                            Some major design flaws   \n",
       "1             1049   50                                   My favorite buy!   \n",
       "2              847   47                                   Flattering shirt   \n",
       "3             1080   49                            Not for the very petite   \n",
       "4              858   39                               Cagrcoal shimmer fun   \n",
       "...            ...  ...                                                ...   \n",
       "19657         1104   34                     Great dress for many occasions   \n",
       "19658          862   48                         Wish it was made of cotton   \n",
       "19659         1104   31                              Cute, but see through   \n",
       "19660         1084   28  Very cute dress, perfect for summer parties an...   \n",
       "19661         1104   52                    Please make more like this one!   \n",
       "\n",
       "                                             Review Text  Rating  \\\n",
       "0      I had such high hopes for this dress and reall...       3   \n",
       "1      I love, love, love this jumpsuit. it's fun, fl...       5   \n",
       "2      This shirt is very flattering to all due to th...       5   \n",
       "3      I love tracy reese dresses, but this one is no...       2   \n",
       "4      I aded this in my basket at hte last mintue to...       5   \n",
       "...                                                  ...     ...   \n",
       "19657  I was very happy to snag this dress at such a ...       5   \n",
       "19658  It reminds me of maternity clothes. soft, stre...       3   \n",
       "19659  This fit well, but the top was very see throug...       3   \n",
       "19660  I bought this dress for a wedding i have this ...       3   \n",
       "19661  This dress in a lovely platinum is feminine an...       5   \n",
       "\n",
       "       Recommended IND  Positive Feedback Count   Division Name  \\\n",
       "0                    0                        0         General   \n",
       "1                    1                        0  General Petite   \n",
       "2                    1                        6         General   \n",
       "3                    0                        4         General   \n",
       "4                    1                        1  General Petite   \n",
       "...                ...                      ...             ...   \n",
       "19657                1                        0  General Petite   \n",
       "19658                1                        0  General Petite   \n",
       "19659                0                        1  General Petite   \n",
       "19660                1                        2         General   \n",
       "19661                1                       22  General Petite   \n",
       "\n",
       "      Department Name Class Name  \\\n",
       "0             Dresses    Dresses   \n",
       "1             Bottoms      Pants   \n",
       "2                Tops    Blouses   \n",
       "3             Dresses    Dresses   \n",
       "4                Tops      Knits   \n",
       "...               ...        ...   \n",
       "19657         Dresses    Dresses   \n",
       "19658            Tops      Knits   \n",
       "19659         Dresses    Dresses   \n",
       "19660         Dresses    Dresses   \n",
       "19661         Dresses    Dresses   \n",
       "\n",
       "                                   Processed Review Text  \n",
       "0      [high, hopes, wanted, work, initially, petite,...  \n",
       "1      [jumpsuit, fun, flirty, fabulous, time, compli...  \n",
       "2      [shirt, due, adjustable, front, tie, length, l...  \n",
       "3      [tracy, reese, dresses, petite, feet, tall, br...  \n",
       "4      [basket, hte, person, store, pick, teh, pale, ...  \n",
       "...                                                  ...  \n",
       "19657       [happy, snag, price, easy, slip, cut, combo]  \n",
       "19658  [reminds, maternity, clothes, stretchy, shiny,...  \n",
       "19659               [worked, glad, store, order, online]  \n",
       "19660  [wedding, summer, medium, waist, perfectly, lo...  \n",
       "19661  [lovely, feminine, perfectly, easy, comfy, hig...  \n",
       "\n",
       "[19652 rows x 11 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping the rows with empty lists\n",
    "df_cleaned = clothes_review_data[clothes_review_data['Processed Review Text'].apply(lambda x: len(x) != 0)] # [2]\n",
    "df_cleaned # checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross verifying if there exists any empty reviews in the cleaned dataframe\n",
    "empty_lists = df_cleaned['Processed Review Text'].apply(lambda x: len(x) == 0).sum() # [2]\n",
    "empty_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  7529\n",
      "Total number of tokens:  355505\n",
      "Lexical diversity:  0.021178323792914306\n",
      "Total number of reviews: 19652\n",
      "Average document length: 18.09001628332994\n",
      "Maximum document length: 47\n",
      "Minimum document length: 1\n",
      "Standard deviation of document length: 8.826348342078324\n"
     ]
    }
   ],
   "source": [
    "stats_print(df_cleaned['Processed Review Text']) # statistics on processed reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I reset the index of the DataFrame because, when I drop rows with empty reviews, their corresponding indices are also removed. It's good practice to reset the index before exporting the data to maintain readability and avoid potential issues in future tasks. A sequential index ensures clarity and consistency in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting the index of the dataframe\n",
    "df_cleaned = df_cleaned.reset_index(drop=True) # [3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving required outputs\n",
    "Saving the requested information as per specification.\n",
    "- processed.csv\n",
    "- vocab.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the processed data 'processed.csv' file\n",
    "df_cleaned.to_csv('processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a-cup',\n",
       " 'a-flutter',\n",
       " 'a-frame',\n",
       " 'a-kind',\n",
       " 'a-line',\n",
       " 'a-lines',\n",
       " 'a-symmetric',\n",
       " 'aa',\n",
       " 'ab',\n",
       " 'abbey',\n",
       " 'abby',\n",
       " 'abdomen',\n",
       " 'ability',\n",
       " 'abnormally',\n",
       " 'abo',\n",
       " 'abou',\n",
       " 'above-the',\n",
       " 'abroad',\n",
       " 'abs',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutley',\n",
       " 'absolutly',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'abt',\n",
       " 'abundance',\n",
       " 'ac',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accenting',\n",
       " 'accents',\n",
       " 'accentuate',\n",
       " 'accentuated',\n",
       " 'accentuates',\n",
       " 'accentuating',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accessories',\n",
       " 'accessorize',\n",
       " 'accessorized',\n",
       " 'accessorizing',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accommodate',\n",
       " 'accommodated',\n",
       " 'accommodates',\n",
       " 'accommodating',\n",
       " 'accomodate',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accordian',\n",
       " 'account',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'acetate',\n",
       " 'achieve',\n",
       " 'acrylic',\n",
       " 'act',\n",
       " 'action',\n",
       " 'active',\n",
       " 'activewear',\n",
       " 'activities',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actuality',\n",
       " 'ad',\n",
       " 'ada',\n",
       " 'add',\n",
       " 'add-on',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'address',\n",
       " 'adds',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adjust',\n",
       " 'adjustable',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admiring',\n",
       " 'admit',\n",
       " 'admittedly',\n",
       " 'adn',\n",
       " 'ador',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'adventure',\n",
       " 'advertised',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'aesthetic',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affects',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'aforementioned',\n",
       " 'afraid',\n",
       " 'afternoon',\n",
       " 'afterward',\n",
       " 'ag',\n",
       " \"ag's\",\n",
       " 'age',\n",
       " 'age-appropriate',\n",
       " 'aged',\n",
       " 'ages',\n",
       " 'aggressive',\n",
       " 'agin',\n",
       " 'ago',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'ags',\n",
       " 'ah',\n",
       " 'ahd',\n",
       " 'ahead',\n",
       " 'ahhh',\n",
       " 'ahs',\n",
       " 'ahve',\n",
       " 'air',\n",
       " 'air-dried',\n",
       " 'air-drying',\n",
       " 'airiness',\n",
       " 'airing',\n",
       " 'airplanes',\n",
       " 'airport',\n",
       " 'airy',\n",
       " 'aize',\n",
       " 'aka',\n",
       " 'akemi',\n",
       " 'al',\n",
       " 'alas',\n",
       " 'alaska',\n",
       " 'albeit',\n",
       " 'alexandria',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'alike',\n",
       " 'aline',\n",
       " 'alittle',\n",
       " 'all-around',\n",
       " 'all-in',\n",
       " 'all-over',\n",
       " 'alley',\n",
       " 'allison',\n",
       " 'allover',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allusion',\n",
       " 'alot',\n",
       " 'alpaca',\n",
       " 'alright',\n",
       " 'als',\n",
       " 'alter',\n",
       " 'alteration',\n",
       " 'alterations',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternate',\n",
       " 'alternations',\n",
       " 'alternative',\n",
       " 'altho',\n",
       " 'altogether',\n",
       " 'amadi',\n",
       " 'amalfi',\n",
       " 'amazed',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'ambiguous',\n",
       " 'amd',\n",
       " 'american',\n",
       " 'amount',\n",
       " 'amounts',\n",
       " 'amp',\n",
       " 'ample',\n",
       " 'amply',\n",
       " 'amterial',\n",
       " 'anatomy',\n",
       " 'and-go',\n",
       " 'angel',\n",
       " 'angeles',\n",
       " 'angle',\n",
       " 'angled',\n",
       " 'angles',\n",
       " 'angora',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'ankle',\n",
       " 'ankle-length',\n",
       " 'ankles',\n",
       " \"ann's\",\n",
       " 'anna',\n",
       " 'anniversary',\n",
       " 'annoyance',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'anorak',\n",
       " 'ans',\n",
       " 'answer',\n",
       " 'ant',\n",
       " 'anth',\n",
       " 'anther',\n",
       " 'antho',\n",
       " 'anticipate',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'anticipation',\n",
       " 'antique',\n",
       " 'antrho',\n",
       " 'antro',\n",
       " 'anxious',\n",
       " 'anxiously',\n",
       " 'anymore',\n",
       " \"anyone's\",\n",
       " 'anytime',\n",
       " 'app',\n",
       " 'appalled',\n",
       " 'apparel',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealed',\n",
       " 'appealing',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'apple',\n",
       " 'apple-shaped',\n",
       " 'applied',\n",
       " 'appliqu',\n",
       " 'applique',\n",
       " 'apply',\n",
       " 'appreciated',\n",
       " 'apprehensive',\n",
       " 'approach',\n",
       " 'approaching',\n",
       " 'appropriately',\n",
       " 'approved',\n",
       " 'approx',\n",
       " 'approximate',\n",
       " 'approximately',\n",
       " 'apprx',\n",
       " 'apricot',\n",
       " 'april',\n",
       " 'apron',\n",
       " 'apt',\n",
       " 'aqua',\n",
       " 'ar',\n",
       " 'arc',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'arielle',\n",
       " 'arm',\n",
       " 'arm-holes',\n",
       " 'armed',\n",
       " 'armhole',\n",
       " 'armholes',\n",
       " 'armpit',\n",
       " 'armpits',\n",
       " 'arms',\n",
       " 'army',\n",
       " 'arranged',\n",
       " 'arrival',\n",
       " 'arrivals',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arrows',\n",
       " 'art',\n",
       " 'article',\n",
       " 'articles',\n",
       " 'artist',\n",
       " \"artist's\",\n",
       " 'artistic',\n",
       " 'artsy',\n",
       " 'artwork',\n",
       " 'arty-looking',\n",
       " 'as-is',\n",
       " 'as-pictured',\n",
       " 'asap',\n",
       " 'ashley',\n",
       " 'asia',\n",
       " 'asked',\n",
       " 'aspect',\n",
       " 'aspects',\n",
       " 'assessing',\n",
       " 'assets',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'associate',\n",
       " 'associates',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'assured',\n",
       " 'astounded',\n",
       " 'asymmetric',\n",
       " 'asymmetrical',\n",
       " 'asymmetry',\n",
       " 'ate',\n",
       " 'athleisure',\n",
       " 'athlete',\n",
       " 'athletic',\n",
       " 'atl',\n",
       " 'atlanta',\n",
       " 'atleast',\n",
       " 'atrocious',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attaches',\n",
       " 'attachment',\n",
       " 'attempt',\n",
       " 'attempted',\n",
       " 'attempting',\n",
       " 'attend',\n",
       " 'attendant',\n",
       " 'attended',\n",
       " 'attending',\n",
       " 'attention',\n",
       " 'attire',\n",
       " 'attitude',\n",
       " 'attracted',\n",
       " 'attracting',\n",
       " 'attractive',\n",
       " 'audrey',\n",
       " 'august',\n",
       " 'aunt',\n",
       " 'australian',\n",
       " 'authentic',\n",
       " 'automatically',\n",
       " 'autumn',\n",
       " 'autumnal',\n",
       " 'avail',\n",
       " 'availability',\n",
       " 'average',\n",
       " 'avid',\n",
       " 'avoid',\n",
       " 'avoided',\n",
       " 'avoiding',\n",
       " 'avoids',\n",
       " 'awaited',\n",
       " 'awaiting',\n",
       " 'awards',\n",
       " 'aware',\n",
       " 'awesome',\n",
       " 'awful',\n",
       " 'awhile',\n",
       " 'awkward',\n",
       " 'awkwardly',\n",
       " 'awkwardness',\n",
       " 'az',\n",
       " 'b-c',\n",
       " 'ba',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'baby-doll',\n",
       " 'babydoll',\n",
       " 'bac',\n",
       " 'bachelorette',\n",
       " 'back-ordered',\n",
       " 'back-up',\n",
       " 'backed',\n",
       " 'background',\n",
       " 'backorder',\n",
       " 'backordered',\n",
       " 'backpack',\n",
       " 'backs',\n",
       " 'backside',\n",
       " 'backup',\n",
       " 'backward',\n",
       " 'backwards',\n",
       " 'backyard',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'bag',\n",
       " 'bagged',\n",
       " 'baggie',\n",
       " 'baggier',\n",
       " 'bagginess',\n",
       " 'bagging',\n",
       " 'baggy',\n",
       " 'bags',\n",
       " 'bailey',\n",
       " 'baily',\n",
       " 'balance',\n",
       " 'balanced',\n",
       " 'balances',\n",
       " 'balck',\n",
       " 'balked',\n",
       " 'ball',\n",
       " 'ballet',\n",
       " 'balloon',\n",
       " 'ballooned',\n",
       " 'balloons',\n",
       " 'balloony',\n",
       " 'balls',\n",
       " 'bam',\n",
       " 'band',\n",
       " 'bandage',\n",
       " 'bandeau',\n",
       " 'banded',\n",
       " 'banding',\n",
       " 'bands',\n",
       " 'bank',\n",
       " 'bar',\n",
       " 'barbecue',\n",
       " 'bare',\n",
       " 'barefoot',\n",
       " 'barely',\n",
       " 'bargain',\n",
       " 'barley',\n",
       " 'baroque',\n",
       " 'barre',\n",
       " 'barrel',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'based',\n",
       " 'basic',\n",
       " 'basically',\n",
       " 'basics',\n",
       " 'basis',\n",
       " 'basket',\n",
       " 'basketball',\n",
       " 'basketweave',\n",
       " 'bat',\n",
       " 'batch',\n",
       " 'batches',\n",
       " 'bath',\n",
       " 'bathing',\n",
       " 'bathrobe',\n",
       " 'bathroom',\n",
       " 'battle',\n",
       " 'batwing',\n",
       " 'batwings',\n",
       " 'bay',\n",
       " 'bbq',\n",
       " 'bc',\n",
       " 'bday',\n",
       " 'bea',\n",
       " 'beach',\n",
       " 'beachy',\n",
       " 'bead',\n",
       " 'beaded',\n",
       " 'beading',\n",
       " 'beads',\n",
       " 'beadwork',\n",
       " 'bear',\n",
       " 'beat',\n",
       " 'beauties',\n",
       " 'beautifu',\n",
       " 'beautiful',\n",
       " 'beautifully',\n",
       " 'beautify',\n",
       " 'beauty',\n",
       " 'bec',\n",
       " 'beca',\n",
       " 'becasue',\n",
       " 'becau',\n",
       " 'becaus',\n",
       " 'becuase',\n",
       " 'bed',\n",
       " 'bedtime',\n",
       " 'bee',\n",
       " 'beef',\n",
       " 'bees',\n",
       " 'began',\n",
       " 'begging',\n",
       " 'begin',\n",
       " 'beginning',\n",
       " 'begins',\n",
       " 'behold',\n",
       " 'beige',\n",
       " 'bein',\n",
       " 'bel',\n",
       " 'bell',\n",
       " 'bell-sleeve',\n",
       " 'belled',\n",
       " 'bellow',\n",
       " 'bells',\n",
       " 'belly',\n",
       " 'bellybutton',\n",
       " 'belonged',\n",
       " 'beloved',\n",
       " 'belt',\n",
       " 'belted',\n",
       " 'belting',\n",
       " 'belts',\n",
       " 'bend',\n",
       " 'bending',\n",
       " 'beneath',\n",
       " 'benefit',\n",
       " 'bent',\n",
       " 'bermuda',\n",
       " 'berry',\n",
       " 'bes',\n",
       " 'bet',\n",
       " 'bette',\n",
       " 'betty',\n",
       " 'beware',\n",
       " 'bf',\n",
       " 'bff',\n",
       " 'bi',\n",
       " 'bias',\n",
       " 'biased',\n",
       " 'bib',\n",
       " 'bicep',\n",
       " 'biceps',\n",
       " 'bicycle',\n",
       " 'bid',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'biggie',\n",
       " 'biggish',\n",
       " 'biker',\n",
       " 'bikini',\n",
       " 'bikinis',\n",
       " 'bill',\n",
       " 'billow',\n",
       " 'billowed',\n",
       " 'billowing',\n",
       " 'billows',\n",
       " 'billowy',\n",
       " 'bind',\n",
       " 'binder',\n",
       " 'binding',\n",
       " 'bingo',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birkenstocks',\n",
       " 'birth',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bite',\n",
       " 'bits',\n",
       " 'bitter',\n",
       " 'bizarre',\n",
       " 'bl',\n",
       " 'black',\n",
       " 'black-and',\n",
       " 'blacks',\n",
       " 'blades',\n",
       " 'blah',\n",
       " 'bland',\n",
       " 'blank',\n",
       " 'blanket',\n",
       " 'blankets',\n",
       " 'blazer',\n",
       " 'blazers',\n",
       " 'blazing',\n",
       " 'bleach',\n",
       " 'bleached',\n",
       " 'bled',\n",
       " 'bleed',\n",
       " 'blend',\n",
       " 'blends',\n",
       " 'blessed',\n",
       " 'blight',\n",
       " 'blindly',\n",
       " 'bling',\n",
       " 'blk',\n",
       " 'bloated',\n",
       " 'blob',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blocking',\n",
       " 'blocks',\n",
       " 'blog',\n",
       " 'blogger',\n",
       " 'blond',\n",
       " 'blonde',\n",
       " 'blood',\n",
       " 'bloom',\n",
       " 'blossoms',\n",
       " 'blotchy',\n",
       " 'blouse',\n",
       " 'blouse-y',\n",
       " 'bloused',\n",
       " 'blouses',\n",
       " 'blousey',\n",
       " 'blousing',\n",
       " 'blouson',\n",
       " 'blousy',\n",
       " 'blow',\n",
       " 'blown',\n",
       " 'blows',\n",
       " 'blowzy',\n",
       " 'blu',\n",
       " 'blue',\n",
       " 'blue-green',\n",
       " 'blue-grey',\n",
       " 'blue-ish',\n",
       " 'blueish',\n",
       " 'blues',\n",
       " 'bluish',\n",
       " 'bluishgreen',\n",
       " 'blush',\n",
       " 'bo',\n",
       " 'board',\n",
       " 'boarder',\n",
       " 'boardwalk',\n",
       " 'boat',\n",
       " 'boat-neck',\n",
       " 'boatneck',\n",
       " 'bod',\n",
       " 'bodice',\n",
       " 'bodies',\n",
       " 'body',\n",
       " 'body-hugging',\n",
       " 'body-skimming',\n",
       " 'body-type',\n",
       " 'bodycon',\n",
       " 'bodysuit',\n",
       " 'bodytype',\n",
       " 'bog',\n",
       " 'bohemian',\n",
       " 'boho',\n",
       " 'boho-chic',\n",
       " 'boiled',\n",
       " 'bold',\n",
       " 'bolder',\n",
       " 'bolero',\n",
       " 'bomb',\n",
       " 'bomber',\n",
       " 'bomber-style',\n",
       " 'bone',\n",
       " 'boned',\n",
       " 'bones',\n",
       " 'boning',\n",
       " 'bonnet',\n",
       " 'bonus',\n",
       " 'boo',\n",
       " 'boob',\n",
       " 'boobs',\n",
       " 'book',\n",
       " 'books',\n",
       " 'boost',\n",
       " 'boot',\n",
       " 'bootcut',\n",
       " 'bootie',\n",
       " 'booties',\n",
       " 'boots',\n",
       " 'booty',\n",
       " 'bordeaux',\n",
       " 'border',\n",
       " 'bordered',\n",
       " 'borderline',\n",
       " 'borders',\n",
       " 'boring',\n",
       " 'born',\n",
       " 'borrow',\n",
       " 'borrowed',\n",
       " 'bosom',\n",
       " 'boston',\n",
       " 'bot',\n",
       " 'bother',\n",
       " 'bothered',\n",
       " 'bothers',\n",
       " 'bothersome',\n",
       " 'bottom',\n",
       " 'bottom-heavy',\n",
       " 'bottoms',\n",
       " 'bottons',\n",
       " 'boucle',\n",
       " 'bough',\n",
       " 'bounce',\n",
       " 'bouncy',\n",
       " 'bow',\n",
       " 'bows',\n",
       " 'box',\n",
       " 'boxes',\n",
       " 'boxier',\n",
       " 'boxiness',\n",
       " 'boxing',\n",
       " 'boxy',\n",
       " 'boy',\n",
       " 'boyfriend',\n",
       " 'boyfriends',\n",
       " 'boyish',\n",
       " 'boyleg',\n",
       " 'boys',\n",
       " 'br',\n",
       " 'bra',\n",
       " 'bra-less',\n",
       " 'bra-straps',\n",
       " 'bracelet',\n",
       " 'braided',\n",
       " 'brainer',\n",
       " 'braless',\n",
       " 'bralette',\n",
       " 'bralettes',\n",
       " 'branch',\n",
       " 'branches',\n",
       " 'brand',\n",
       " 'brands',\n",
       " 'bras',\n",
       " 'brass',\n",
       " 'break',\n",
       " 'breaker',\n",
       " 'breakers',\n",
       " 'breaking',\n",
       " 'breaks',\n",
       " 'breast',\n",
       " 'breasted',\n",
       " 'breastfeeding',\n",
       " 'breasting',\n",
       " 'breasts',\n",
       " 'breath',\n",
       " 'breathable',\n",
       " 'breathe',\n",
       " 'breathes',\n",
       " 'breathing',\n",
       " 'breathtaking',\n",
       " 'breeze',\n",
       " 'breezy',\n",
       " 'breton',\n",
       " 'brick',\n",
       " 'bridal',\n",
       " 'bride',\n",
       " 'bridesmaid',\n",
       " 'bridesmaids',\n",
       " 'briefly',\n",
       " 'briefs',\n",
       " 'bright',\n",
       " 'brighten',\n",
       " 'brightens',\n",
       " 'brighter',\n",
       " 'brightness',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'brioche',\n",
       " 'brisk',\n",
       " 'british',\n",
       " 'broach',\n",
       " 'broad',\n",
       " 'broad-shouldered',\n",
       " 'broaden',\n",
       " 'broadened',\n",
       " 'broader',\n",
       " 'brocade',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'bronze',\n",
       " 'brooklyn',\n",
       " \"brother's\",\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brownish',\n",
       " 'browns',\n",
       " 'browse',\n",
       " 'browsing',\n",
       " 'brunch',\n",
       " 'brunette',\n",
       " 'brush',\n",
       " 'brushed',\n",
       " 'brushing',\n",
       " 'bs',\n",
       " 'btu',\n",
       " 'btw',\n",
       " 'bu',\n",
       " 'bubble',\n",
       " 'bubble-like',\n",
       " 'bubbled',\n",
       " 'bubbles',\n",
       " 'buckle',\n",
       " 'buckled',\n",
       " 'buckles',\n",
       " 'bucks',\n",
       " 'budge',\n",
       " 'budget',\n",
       " 'bug',\n",
       " 'bugs',\n",
       " 'build',\n",
       " 'building',\n",
       " 'builds',\n",
       " 'built',\n",
       " 'built-in',\n",
       " 'bulge',\n",
       " 'bulged',\n",
       " 'bulges',\n",
       " 'bulging',\n",
       " 'bulk',\n",
       " 'bulkier',\n",
       " 'bulkiness',\n",
       " 'bulky',\n",
       " 'bullet',\n",
       " 'bum',\n",
       " 'bummed',\n",
       " 'bummer',\n",
       " 'bump',\n",
       " 'bumped',\n",
       " 'bumps',\n",
       " 'bumpy',\n",
       " 'bun',\n",
       " 'bunch',\n",
       " 'bunched',\n",
       " 'bunches',\n",
       " 'bunching',\n",
       " 'bunchy',\n",
       " 'bundle',\n",
       " 'burgers',\n",
       " 'burgundy',\n",
       " 'burlap',\n",
       " 'burn',\n",
       " 'burned',\n",
       " 'burnout',\n",
       " 'burns',\n",
       " 'burnt',\n",
       " 'burst',\n",
       " 'bus',\n",
       " 'business',\n",
       " 'business-casual',\n",
       " 'bust',\n",
       " 'bust-line',\n",
       " 'busted',\n",
       " 'bustier',\n",
       " 'busting',\n",
       " 'bustline',\n",
       " 'busts',\n",
       " 'busty',\n",
       " 'busy',\n",
       " 'butt',\n",
       " 'butter',\n",
       " 'butterflies',\n",
       " 'butterfly',\n",
       " 'buttery',\n",
       " 'button',\n",
       " 'button-down',\n",
       " 'button-front',\n",
       " 'button-up',\n",
       " 'buttondown',\n",
       " 'buttoned',\n",
       " 'buttoned-up',\n",
       " 'buttonhole',\n",
       " 'buttonholes',\n",
       " 'buttoning',\n",
       " 'buttons',\n",
       " 'butts',\n",
       " 'buy',\n",
       " 'buyer',\n",
       " 'buyers',\n",
       " 'buyi',\n",
       " 'buying',\n",
       " 'byron',\n",
       " 'c-cup',\n",
       " 'c-d',\n",
       " 'ca',\n",
       " 'cable',\n",
       " 'cacti',\n",
       " 'cafe',\n",
       " 'caftan',\n",
       " 'cage',\n",
       " 'cake',\n",
       " 'cal',\n",
       " 'calf',\n",
       " 'cali',\n",
       " 'california',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calling',\n",
       " 'calls',\n",
       " 'calves',\n",
       " 'cam',\n",
       " 'camel',\n",
       " 'camera',\n",
       " 'cami',\n",
       " \"cami's\",\n",
       " 'camis',\n",
       " 'camisol',\n",
       " 'camisole',\n",
       " 'camisoles',\n",
       " 'camo',\n",
       " 'camouflage',\n",
       " 'camouflages',\n",
       " 'camouflaging',\n",
       " 'camp',\n",
       " 'campus',\n",
       " 'cancel',\n",
       " 'cancelled',\n",
       " 'cancer',\n",
       " 'canvas',\n",
       " 'canvas-y',\n",
       " 'cap',\n",
       " 'cape',\n",
       " 'capes',\n",
       " 'capped',\n",
       " 'capri',\n",
       " 'capris',\n",
       " 'capsule',\n",
       " 'capture',\n",
       " 'car',\n",
       " 'caramel',\n",
       " 'carbon',\n",
       " 'card',\n",
       " 'cardi',\n",
       " 'cardigan',\n",
       " 'cardigans',\n",
       " 'cardio',\n",
       " 'cardis',\n",
       " 'care',\n",
       " 'carefree',\n",
       " 'careful',\n",
       " 'carefully',\n",
       " 'cares',\n",
       " 'cargo',\n",
       " 'cargos',\n",
       " 'caribbean',\n",
       " 'carissima',\n",
       " 'carpet',\n",
       " 'carried',\n",
       " 'carries',\n",
       " 'carry',\n",
       " 'carrying',\n",
       " 'cart',\n",
       " 'cartonnier',\n",
       " 'cartoon',\n",
       " 'cartoonish',\n",
       " 'cas',\n",
       " 'cascade',\n",
       " 'cascades',\n",
       " 'case',\n",
       " 'cases',\n",
       " 'cash',\n",
       " 'cashier',\n",
       " 'cashmere',\n",
       " 'casing',\n",
       " 'casu',\n",
       " 'casual',\n",
       " 'casually',\n",
       " 'cat',\n",
       " 'catalog',\n",
       " 'catalogue',\n",
       " 'catch',\n",
       " 'catcher',\n",
       " 'catches',\n",
       " 'catching',\n",
       " 'catchy',\n",
       " 'categorized',\n",
       " 'category',\n",
       " 'cats',\n",
       " 'caught',\n",
       " 'causal',\n",
       " 'caused',\n",
       " 'causing',\n",
       " 'caution',\n",
       " 'cautious',\n",
       " 'cave',\n",
       " 'caveat',\n",
       " 'caved',\n",
       " 'cc',\n",
       " 'ceases',\n",
       " 'cedar',\n",
       " 'cehst',\n",
       " 'celadon',\n",
       " 'celebrate',\n",
       " 'celebration',\n",
       " 'cell',\n",
       " 'cellophane',\n",
       " 'cellulite',\n",
       " 'center',\n",
       " 'centered',\n",
       " 'cents',\n",
       " 'ceremony',\n",
       " 'ch',\n",
       " 'chain',\n",
       " 'chair',\n",
       " 'challenge',\n",
       " 'challenged',\n",
       " 'challenges',\n",
       " 'challenging',\n",
       " ...]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining list of reviews into a single list and then getting only unique set of words and ordering the reviews alphabetically\n",
    "vocabulary = sorted(set(chain.from_iterable(processed_reviews))) # [4]\n",
    "vocabulary # checking the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1] w07_act1_gen_feat_vec.ipynb - cell 55\n",
    "out_file = open(\"./vocab.txt\", 'w') # creating a file and opening it in write mode\n",
    "\n",
    "# looping through each word in the vocabulary using its index \n",
    "for ind in range(0, len(vocabulary)):\n",
    "    out_file.write(f\"{vocabulary[ind]}:{ind}\\n\") # writing to a file in 'word_string:word_integer_index' format\n",
    "                   \n",
    "out_file.close() # closing the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This part of the assignment highlights the importance of text pre-processing and its vital role in building machine learning models. This task is fundamental for preparing text data for further analysis, such as creating document vectors and feeding these vector representations into machine learning models for classification. It is crucial to follow the exact formatting requirements, especially for the vocabulary file, to ensure compatibility with subsequent tasks. In addition, the activities and lectorial material are designed perfectly to carry out these tasks and helped me understand the concepts thoroughly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] Canvas/Modules/Week 7 - Activities/w07_activities/w07_act1_gen_feat_vec.ipynb https://rmit.instructure.com/courses/125024/pages/week-7-activities-2?module_item_id=6449422 <br>\n",
    "[2] Usage of apply(): https://stackoverflow.com/questions/36213383/pandas-dataframe-how-to-apply-function-to-a-specific-column <br>\n",
    "[3] Usage of reset_index(): https://stackoverflow.com/questions/20490274/how-to-reset-index-in-a-pandas-dataframe <br>\n",
    "[4] Usage of sorted(): https://stackoverflow.com/questions/32072076/find-the-unique-values-in-a-column-and-then-sort-them <br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
